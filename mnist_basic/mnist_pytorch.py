# -*- coding: utf-8 -*-
"""mnist_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r_11ZDCQWwch_5qqqgurGL3PZZWtUu5J
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.model_selection import train_test_split
import torch.optim
import torch.utils.data
from torch.autograd import Variable

from sklearn.datasets import fetch_openml
mnist=fetch_openml('mnist_784',version=1)
mnist.keys()

x, y = mnist["data"], mnist["target"]
y=y.astype(np.uint8)
print(x.shape,y.shape)
x_train,x_test,y_train,y_test=x[:42000],x[42000:],y[:42000],y[42000:]

BATCH_SIZE=250
torch_x_train=torch.from_numpy(x_train).type(torch.LongTensor)
torch_y_train=torch.from_numpy(y_train).type(torch.LongTensor)
torch_x_test=torch.from_numpy(x_test).type(torch.LongTensor)
torch_y_test=torch.from_numpy(y_test).type(torch.LongTensor)
torch_x_train = torch_x_train.view(-1, 1,28,28).float()
torch_x_test = torch_x_test.view(-1,1,28,28).float()
print(torch_x_train.shape)
print(torch_x_test.shape)

train=torch.utils.data.TensorDataset(torch_x_train,torch_y_train)
test=torch.utils.data.TensorDataset(torch_x_test,torch_y_test)
train_loader=torch.utils.data.DataLoader(train,batch_size=BATCH_SIZE,shuffle=False)
test_loader=(torch.utils.data.DataLoader(test,batch_size=BATCH_SIZE,shuffle=False))

def fit(model, train_loader):
    optimizer = torch.optim.Adam(model.parameters())
    error = nn.CrossEntropyLoss()
    EPOCHS = 6
    model.train()
    for epoch in range(EPOCHS):
        correct = 0
        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):
            var_x_batch = Variable(x_batch).float()
            var_y_batch = Variable(y_batch)
            optimizer.zero_grad()
            output = model(var_x_batch)
            loss = error(output, var_y_batch)
            loss.backward()
            optimizer.step()

            # Total correct predictions
            predicted = torch.max(output.data, 1)[1] 
            correct += (predicted == var_y_batch).sum()
            #print(correct)
            if batch_idx % 50 == 0:
                print('Epoch : {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\t Accuracy:{:.3f}%'.format(
                    epoch+1, batch_idx*len(x_batch), len(train_loader.dataset), 100*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))

def evaluate(model):
    correct = 0 
    for test_imgs, test_labels in test_loader:
        #print(test_imgs.shape)
        test_imgs = Variable(test_imgs).float()
        output = model(test_imgs)
        predicted = torch.max(output,1)[1]
        correct += (predicted == test_labels).sum()
    print("Test accuracy:{:.3f}% ".format( float(correct) / (len(test_loader)*BATCH_SIZE)))

class cnn(nn.Module):
  def __init__(self):
    super(cnn, self).__init__()
    self.conv1=nn.Conv2d(1,40,5)
    self.conv2=nn.Conv2d(40,50,3,padding=1)
    self.conv3=nn.Conv2d(50,60,3,padding=1)
    self.fc1=nn.Linear(60*3*3,393)
    self.fc2=nn.Linear(393,159)
    self.fc3=nn.Linear(159,10)
  
  
  def forward(self,x):
    x = F.relu(self.conv1(x))
    x = F.max_pool2d(x, 2, 2)
    x = F.relu(self.conv2(x))
    x = F.max_pool2d(x, 2, 2)
    x = F.relu(self.conv3(x))
    x = F.max_pool2d(x, 2, 2)    
    x = x.view(-1,3*3*60)
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = self.fc3(x)
    return F.log_softmax(x, dim=1)
CNN=cnn()
print(CNN)
it = iter(train_loader)
x_batch, y_batch = next(it)

CNN.forward(x_batch).size()

fit(CNN,train_loader)

evaluate(CNN)